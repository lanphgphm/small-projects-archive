{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Natural Language Processing - Homework 1\n",
    "\n",
    "Pham Lan Phuong - 210120"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import nltk\n",
    "import numpy as np "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('testing_data.txt', 'r') as f:\n",
    "    test_data = f.read()\n",
    "\n",
    "with open('training_data.txt', 'r') as f:\n",
    "    train_data = f.read()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 1\n",
    "Find all sentences that contain “to be” verbs (i.e. “is”, “are”, ...) in the training data\n",
    "file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of sentences that has to-be:  8\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['As part of the major, students will be equipped with the foundational knowledge in Computer Science and relevant disciplines.',\n",
       " 'They will be exposed to essential areas of the CS discipline including theory, systems, and applications.',\n",
       " 'They will learn about the underlying mathematical ideas that are critical for computation, establish proficiency in the process of designing systems and applications, gain experience in collecting and analyzing data using modern technologies, and begin to develop an understanding for the role of users in the design of systems and applications.',\n",
       " 'The Computer Science major at Fulbright is designed to prepare students for work in industry or continue their lifelong learning as well as potential graduate-level studies.',\n",
       " 'All students are first required to take the core courses in Liberal Arts and Science.',\n",
       " 'In addition to the two courses in “Global Humanities and Social Change”, and “Modern Vietnamese Culture and Society”, they will be exposed to computational thinking as part of Fulbright’s undergraduate core courses in “Quantitative Reasoning for a Digital Age.”, “Scientific Inquiry”, and “Design and Systems Thinking”.',\n",
       " 'They will be then equipped with the knowledge in the foundational courses in Computer Science including the courses that will lay out the Mathematics Foundation, Software Foundation, and Hardware Foundation, and one course in Professional Responsibilities and Ethics in CS.',\n",
       " 'After having the knowledge in the CS foundation courses, the students will continue their journey with the major courses, which are designed to cover the most important and basic knowledge in the major aspects in Computer Science including a series of six courses that prepare for them to pursue their studies in the concentration areas of Computer Science.']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences = nltk.tokenize.sent_tokenize(train_data)\n",
    "be_sentences = []\n",
    "for sentence in sentences:\n",
    "    # use re.search() because we care if the sentence contains 'be' or not\n",
    "    contains_be = re.search(r'\\b(is|are|am|be|being|been|was|were)\\b', sentence)\n",
    "    if contains_be:\n",
    "        be_sentences.append(sentence)\n",
    "\n",
    "print(\"Number of sentences that has to-be: \", len(be_sentences))\n",
    "be_sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 2\n",
    "Build a unigram model and a bigram model (both are with add-one smoothing) from the training data file. Then calculate and compare the perplexity score of these two models\n",
    "on the testing data file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unigram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Class Unigram: for unigram language model.\n",
    "\n",
    "Attributes: \n",
    "- n_unigrams: number of tokens in training data \n",
    "- vocab_size: number of unique unigram in training data\n",
    "- count: a dictionary of unigram counts\n",
    "\n",
    "Methods: \n",
    "- train(train_data): train the unigram model\n",
    "- compute_prob(unigram): compute the probability of a unigram using \n",
    "                        unigram count and add-one smoothing\n",
    "- test_perplexity(test_data): compute the perplexity of test data using \n",
    "                        log likelihood method to avoid underflow\n",
    "'''\n",
    "\n",
    "class Unigram: \n",
    "    def __init__(self):\n",
    "        self.n_unigram = 0\n",
    "        self.vocab_size = 0 \n",
    "        self.count = {} \n",
    "        \n",
    "    def train(self, train_data): \n",
    "        ''' \n",
    "        This function trains the unigram model. After running this funtion, \n",
    "        a dictionary storing counts of each unigram will be created.\n",
    "\n",
    "        Input: \n",
    "            train_data: string \n",
    "                training data to train the unigram model\n",
    "        Return: \n",
    "            None \n",
    "        '''\n",
    "        # tokenize & assigning values to model attributes \n",
    "        unigrams = nltk.tokenize.word_tokenize(train_data)\n",
    "        self.count[\"<UNK>\"] = 0\n",
    "        self.n_unigram = len(unigrams)\n",
    "        self.vocab_size = len(set(unigrams)) \n",
    "\n",
    "        # creating unigram count dictionary\n",
    "        for unigram in unigrams:\n",
    "            if unigram in self.count.keys(): \n",
    "                self.count[unigram] += 1 \n",
    "            else: \n",
    "                self.count[unigram] = 1 \n",
    "        \n",
    "\n",
    "    def compute_prob(self, unigram):\n",
    "        '''\n",
    "        This function takes in a unigram, and returns the probability that\n",
    "        unigram appears in the training data with add-one smoothing. \n",
    "\n",
    "        Input: \n",
    "            unigram: string\n",
    "                the unigram to compute probability for\n",
    "        Return:\n",
    "            the probability of the given unigram appearing in the training data\n",
    "        '''\n",
    "        N = self.n_unigram\n",
    "        V = self.vocab_size\n",
    "        if (unigram in self.count.keys()):\n",
    "            return (self.count[unigram] + 1) / (N + V) # smoothing \n",
    "        else: \n",
    "            return 1 / (N + V) # smoothing for unseen words \n",
    "    \n",
    "    def test_perplexity(self, test_data): \n",
    "        ''' \n",
    "        This function takes in a test data, and returns the perplexity \n",
    "        of this data on the unigram model. The perplexity is computed \n",
    "        using log likelihood method to avoid underflow.\n",
    "\n",
    "        Input:\n",
    "            test_data: string\n",
    "                the test data to compute perplexity for\n",
    "        Return:\n",
    "            the perplexity of the test data on the unigram model\n",
    "        '''\n",
    "        test_unigrams = nltk.tokenize.word_tokenize(test_data)\n",
    "        M = len(test_unigrams) \n",
    "\n",
    "        # perplexity = exponential of negative average log likelihood\n",
    "        probs = [] \n",
    "        for unigram in test_unigrams: \n",
    "            probs.append(self.compute_prob(unigram))\n",
    "        \n",
    "        avg_log_likelihood = np.log(probs).sum() / M\n",
    "        ppl = np.exp((-1) * avg_log_likelihood)\n",
    "        return ppl "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "172.11286794438394"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unigram_model = Unigram() \n",
    "unigram_model.train(train_data)\n",
    "\n",
    "unigram_test_ppl = unigram_model.test_perplexity(test_data)\n",
    "unigram_test_ppl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unigrams:  742\n",
      "Number of unique unigrams:  302\n",
      "Unigram test perplexity:  172.11286794438394\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of unigrams: \", unigram_model.n_unigram) \n",
    "print(\"Number of unique unigrams: \", len(unigram_model.count)-1)\n",
    "print(\"Unigram test perplexity: \", unigram_test_ppl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Some of the most common unigrams: \n",
      "  Most Common  Count\n",
      "0           ,     52\n",
      "1         and     37\n",
      "2           .     31\n",
      "3         the     30\n",
      "4          in     27\n",
      "5          of     22\n",
      "6          to     20\n"
     ]
    }
   ],
   "source": [
    "# showing some intermediate results \n",
    "from copy import deepcopy \n",
    "import pandas as pd \n",
    "\n",
    "unicount = deepcopy(unigram_model.count)\n",
    "print(\"Some of the most common unigrams: \")\n",
    "\n",
    "most_common_unigrams = []\n",
    "for i in range(7):\n",
    "    most_common = max(unicount, key=unicount.get)\n",
    "    most_common_unigrams.append({'Most Common': most_common, 'Count': unicount[most_common]})\n",
    "    del unicount[most_common]\n",
    "\n",
    "df = pd.concat([pd.DataFrame(most_common_unigrams)], ignore_index=True)\n",
    "\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bigram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' \n",
    "Class Bigram: for bigram language model. \n",
    "\n",
    "Attributes:\n",
    "- count_unigram: a dictionary of unigram counts\n",
    "- count_bigram: a dictionary of bigram counts\n",
    "- n_unigrams: number of unigram in training data\n",
    "- n_bigrams: number of bigram tokens in training data\n",
    "- vocab_size: number of unique unigram in training data\n",
    "\n",
    "\n",
    "Methods:\n",
    "- get_ngram(n, text): get ngrams from text\n",
    "- count_ngram(ngrams): count ngrams frequency \n",
    "- train(train_data): train the bigram model\n",
    "- compute_prob(bigram): compute the probability of a bigram appearing\n",
    "                        using add-one smoothing\n",
    "- test_perplexity(test_data): compute the perplexity of test data using\n",
    "                        log likelihood method to avoid underflow\n",
    "'''\n",
    "\n",
    "class Bigram: \n",
    "    def __init__(self):\n",
    "        self.count_unigram = {}\n",
    "        self.count_bigram = {} \n",
    "        self.n_unigram = 0\n",
    "        self.n_bigram = 0 \n",
    "\n",
    "        self.vocab_size = 0 \n",
    "        \n",
    "    \n",
    "    def get_ngram(self, n, text): \n",
    "        ''' \n",
    "        This function takes in a text and returns a list of ngrams.\n",
    "        If n = 1, return a list of unigrams using nltk.tokenize module. \n",
    "        Higher ngrams are manually created with sliding window. \n",
    "        \n",
    "        Input:\n",
    "            n: int\n",
    "                the n in 'ngram' \n",
    "            text: string  \n",
    "                the text to be split into ngrams   \n",
    "            \n",
    "        Return:\n",
    "            a list of ngrams\n",
    "        '''\n",
    "        unigrams = nltk.tokenize.word_tokenize(text)\n",
    "        ngrams = [] \n",
    "        if n == 1: \n",
    "            return unigrams \n",
    "        else: \n",
    "            last_start = len(unigrams) - n + 1\n",
    "            for i in range(last_start):\n",
    "                ngram = tuple(unigrams[i: i+n])\n",
    "                ngrams.append(ngram)\n",
    "            return ngrams\n",
    "    \n",
    "    def count_ngram(self, ngrams): \n",
    "        ''' \n",
    "        This function takes in a list of ngrams and returns a dictionary\n",
    "        counting the frequency of each ngram. \n",
    "\n",
    "        Input:\n",
    "            ngrams: list \n",
    "                a list of ngrams    \n",
    "        \n",
    "        Return:\n",
    "            a dictionary of ngram counts\n",
    "        '''\n",
    "        count = {} \n",
    "        count[\"<UNK>\"] = 0\n",
    "        \n",
    "        for ngram in ngrams: \n",
    "            if ngram in count.keys(): \n",
    "                count[ngram] += 1 \n",
    "            else: \n",
    "                count[ngram] = 1 \n",
    "        return count \n",
    "\n",
    "    def train(self, train_data):\n",
    "        ''' \n",
    "        This function trains the bigram model. After running this funtion,\n",
    "        two dictionaries storing counts of each unigram and bigram will be\n",
    "        created.\n",
    "\n",
    "        Input:\n",
    "            train_data: string\n",
    "                training data to train the bigram model\n",
    "        Return:\n",
    "            None\n",
    "        '''\n",
    "        # tokenize unigrams & assigning unigram attributes \n",
    "        unigrams = self.get_ngram(1, train_data)\n",
    "        self.n_unigram = len(unigrams)\n",
    "        self.vocab_size = len(set(unigrams))\n",
    "        self.count_unigram = self.count_ngram(unigrams)\n",
    "\n",
    "        # tokenize bigrams & assigning bigram attributes\n",
    "        bigrams = self.get_ngram(2, train_data)\n",
    "        self.n_bigram = len(bigrams) \n",
    "        self.count_bigram = self.count_ngram(bigrams)\n",
    "\n",
    "    def compute_prob(self, bigram):\n",
    "        '''\n",
    "        This function takes in a bigram, and returns the probability that\n",
    "        bigram appears in the training data with add-one smoothing.\n",
    "\n",
    "        In case of unseen bigrams (a, b): \n",
    "        (1) a is unseen, b is seen:\n",
    "            P(a, b) = (count(a, b) +  1 )/ (count(a) + V)\n",
    "                    = 1 / V\n",
    "        (2) a is seen, b is unseen:\n",
    "            P(a, b) = count(a, b) + 1 / count(a) + V\n",
    "                    = 1 / count(a) + V\n",
    "        (3) a is unseen, b is unseen:\n",
    "            P(a, b) = count(a, b) + 1 / count(a) + V\n",
    "                    = 1 / V\n",
    "        (4) a is seen, b is seen, but in the wrong order:\n",
    "            P(a, b) = count(a, b) + 1 / count(a) + V\n",
    "                    = 1 / count(a) + V\n",
    "\n",
    "        Input:\n",
    "            bigram: tuple\n",
    "                the bigram to compute probability for\n",
    "        Return:\n",
    "            the probability of the given bigram appearing in the training data\n",
    "        '''\n",
    "        ctx = bigram[0]\n",
    "        if (ctx in self.count_unigram.keys()):\n",
    "            context = self.count_unigram[ctx]\n",
    "        else:\n",
    "            context = 0\n",
    "\n",
    "        if (bigram in self.count_bigram.keys()):\n",
    "            joint = self.count_bigram[bigram]\n",
    "        else: \n",
    "            joint = 0 \n",
    "        \n",
    "        return (joint + 1) / (context + self.vocab_size) # smoothing\n",
    "\n",
    "    def test_perplexity(self, test_data): \n",
    "        '''\n",
    "        This function takes in a test data, and returns the perplexity\n",
    "        of this data on the bigram model. The perplexity is computed\n",
    "        using log likelihood method to avoid underflow.\n",
    "\n",
    "        Input:\n",
    "            test_data: string\n",
    "                the test data to compute perplexity for\n",
    "        Return:\n",
    "            the perplexity of the test data on the bigram model \n",
    "        '''\n",
    "        test_bigrams = self.get_ngram(2, test_data)\n",
    "        test_unigrams = self.get_ngram(1, test_data)\n",
    "        M = len(test_unigrams) \n",
    "\n",
    "        probs = [] \n",
    "        \n",
    "        # compute the probability that the first word in test data appears\n",
    "        # P(first) is the probaility that this unigram appears in training data\n",
    "        first_word = test_unigrams[0] \n",
    "        p_first_word = 1\n",
    "        if (first_word in self.count_unigram.keys()): \n",
    "            # if first_word is seen\n",
    "            p_first_word = (self.count_unigram[first_word] + 1) \\\n",
    "                  / (self.n_unigram + self.vocab_size)\n",
    "        else: \n",
    "            # first_word is unseen\n",
    "            p_first_word = 1 / (self.n_unigram + self.vocab_size)\n",
    "\n",
    "        probs.append(p_first_word)\n",
    "\n",
    "        for bigram in test_bigrams: \n",
    "            probs.append(self.compute_prob(bigram))\n",
    "        \n",
    "        avg_log_likelihood = np.log(probs).sum() / M\n",
    "        ppl = np.exp((-1) * avg_log_likelihood)\n",
    "        return ppl "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "209.69428094428645"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bigram_model = Bigram()\n",
    "bigram_model.train(train_data)\n",
    "\n",
    "bigram_test_ppl = bigram_model.test_perplexity(test_data)\n",
    "bigram_test_ppl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of bigrams:  741\n",
      "Number of unique bigrams:  591\n",
      "Bigram test perplexity:  209.69428094428645\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of bigrams: \", bigram_model.n_bigram) \n",
    "print(\"Number of unique bigrams: \", len(bigram_model.count_bigram)-1)\n",
    "print(\"Bigram test perplexity: \", bigram_test_ppl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Some of the most common bigrams: \n",
      "           Most Common  Count\n",
      "0             (,, and)     12\n",
      "1  (Computer, Science)      9\n",
      "2            (in, the)      8\n",
      "3     (Science, major)      4\n",
      "4           (will, be)      4\n",
      "5      (knowledge, in)      4\n",
      "6       (in, Computer)      4\n"
     ]
    }
   ],
   "source": [
    "# showing some intermediate results \n",
    "bicount = deepcopy(bigram_model.count_bigram)\n",
    "print(\"Some of the most common bigrams: \")\n",
    "\n",
    "most_common_bigrams = []\n",
    "for i in range(7):\n",
    "    most_common = max(bicount, key=bicount.get)\n",
    "    most_common_bigrams.append({'Most Common': most_common, 'Count': bicount[most_common]})\n",
    "    del bicount[most_common]\n",
    "\n",
    "df = pd.concat([pd.DataFrame(most_common_bigrams)], ignore_index=True)\n",
    "\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparison: Unigram vs. Bigram "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On the original testing data:\n",
      "Number of unigrams in the testing data:  46\n",
      "Unigram test perplexity:  172.11286794438394\n",
      "Bigram test perplexity:  209.69428094428645\n"
     ]
    }
   ],
   "source": [
    "print(\"On the original testing data:\")\n",
    "print(\"Number of unigrams in the testing data: \", len(nltk.tokenize.word_tokenize(test_data)))\n",
    "print(\"Unigram test perplexity: \", unigram_test_ppl)\n",
    "print(\"Bigram test perplexity: \", bigram_test_ppl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I try to run these 2 models on several more test data to see if Unigram consistently performs better than Bigram. Contrary to my expectation, Bigram performs better than Unigram in texts that are NOT related to Fulbright. \n",
    "\n",
    "In texts relevant to Fulbright or relevant to CS, Unigram performs better than Bigram :) even just by a little bit, it is still better. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On the social science major description data: \n",
      "Number of unigrams in the testing data:  49\n",
      "Unigram test perplexity:  243.84201918052653\n",
      "Bigram test perplexity:  279.4338967244134\n"
     ]
    }
   ],
   "source": [
    "with open('soci.txt', 'r') as f:\n",
    "    soci = f.read()\n",
    "\n",
    "print(\"On the social science major description data: \")\n",
    "print(\"Number of unigrams in the testing data: \", len(nltk.tokenize.word_tokenize(soci)))\n",
    "print(\"Unigram test perplexity: \", unigram_model.test_perplexity(soci))\n",
    "print(\"Bigram test perplexity: \", bigram_model.test_perplexity(soci))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On the about Fulbright data: \n",
      "Number of unigrams in the testing data:  49\n",
      "Unigram test perplexity:  297.37958576446357\n",
      "Bigram test perplexity:  301.22749165121564\n"
     ]
    }
   ],
   "source": [
    "with open('aboutF.txt', 'r') as f:\n",
    "    aboutF = f.read()\n",
    "\n",
    "print(\"On the about Fulbright data: \")\n",
    "print(\"Number of unigrams in the testing data: \", len(nltk.tokenize.word_tokenize(aboutF)))\n",
    "print(\"Unigram test perplexity: \", unigram_model.test_perplexity(aboutF))\n",
    "print(\"Bigram test perplexity: \", bigram_model.test_perplexity(aboutF))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On the CS Wikipedia data: \n",
      "Number of unigrams in the testing data:  46\n",
      "Unigram test perplexity:  164.2326658507244\n",
      "Bigram test perplexity:  241.0606657999618\n"
     ]
    }
   ],
   "source": [
    "with open('cswiki.txt', 'r') as f:\n",
    "    cswiki = f.read()\n",
    "\n",
    "print(\"On the CS Wikipedia data: \") \n",
    "print(\"Number of unigrams in the testing data: \", len(nltk.tokenize.word_tokenize(cswiki)))\n",
    "print(\"Unigram test perplexity: \", unigram_model.test_perplexity(cswiki))\n",
    "print(\"Bigram test perplexity: \", bigram_model.test_perplexity(cswiki))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On the Undertale game description data: \n",
      "Number of unigrams in the testing data:  48\n",
      "Unigram test perplexity:  431.52020218385195\n",
      "Bigram test perplexity:  302.3494724533181\n"
     ]
    }
   ],
   "source": [
    "with open('undertale.txt', 'r') as f:\n",
    "    undertale = f.read()\n",
    "\n",
    "print(\"On the Undertale game description data: \")\n",
    "print(\"Number of unigrams in the testing data: \", len(nltk.tokenize.word_tokenize(undertale)))\n",
    "print(\"Unigram test perplexity: \", unigram_model.test_perplexity(undertale))\n",
    "print(\"Bigram test perplexity: \", bigram_model.test_perplexity(undertale))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On the Egypt Wikipedia data: \n",
      "Number of unigrams in the testing data:  48\n",
      "Unigram test perplexity:  316.2653156458338\n",
      "Bigram test perplexity:  290.3649526192667\n"
     ]
    }
   ],
   "source": [
    "with open('egyptian.txt', 'r') as f:\n",
    "    egyptian = f.read()\n",
    "\n",
    "print(\"On the Egypt Wikipedia data: \")\n",
    "print(\"Number of unigrams in the testing data: \", len(nltk.tokenize.word_tokenize(egyptian)))\n",
    "print(\"Unigram test perplexity: \", unigram_model.test_perplexity(egyptian))\n",
    "print(\"Bigram test perplexity: \", bigram_model.test_perplexity(egyptian))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On the Ghost In The Shell film wiki data: \n",
      "Number of unigrams in the testing data:  60\n",
      "Unigram test perplexity:  355.96280359448326\n",
      "Bigram test perplexity:  272.5486676938591\n"
     ]
    }
   ],
   "source": [
    "with open('ghost.txt', 'r') as f:\n",
    "    ghost = f.read()\n",
    "\n",
    "print(\"On the Ghost In The Shell film wiki data: \")\n",
    "print(\"Number of unigrams in the testing data: \", len(nltk.tokenize.word_tokenize(ghost)))\n",
    "print(\"Unigram test perplexity: \", unigram_model.test_perplexity(ghost))\n",
    "print(\"Bigram test perplexity: \", bigram_model.test_perplexity(ghost))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
