{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Natural Language Processing - Homework 1 \n",
    "\n",
    "Pham Lan Phuong - 210120"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/lanphgphm/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "import nltk\n",
    "from nltk.util import ngrams\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('testing_data.txt', 'r') as f:\n",
    "    test = f.read()\n",
    "\n",
    "with open('training_data.txt', 'r') as f:\n",
    "    train = f.read()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 1\n",
    "Find all sentences that contain “to be” verbs (i.e. “is”, “are”, ...) in the training data\n",
    "file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = nltk.tokenize.sent_tokenize(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['As part of the major, students will be equipped with the foundational knowledge in Computer Science and relevant disciplines.',\n",
       " 'They will be exposed to essential areas of the CS discipline including theory, systems, and applications.',\n",
       " 'They will learn about the underlying mathematical ideas that are critical for computation, establish proficiency in the process of designing systems and applications, gain experience in collecting and analyzing data using modern technologies, and begin to develop an understanding for the role of users in the design of systems and applications.',\n",
       " 'The Computer Science major at Fulbright is designed to prepare students for work in industry or continue their lifelong learning as well as potential graduate-level studies.',\n",
       " 'All students are first required to take the core courses in Liberal Arts and Science.',\n",
       " 'In addition to the two courses in “Global Humanities and Social Change”, and “Modern Vietnamese Culture and Society”, they will be exposed to computational thinking as part of Fulbright’s undergraduate core courses in “Quantitative Reasoning for a Digital Age.”, “Scientific Inquiry”, and “Design and Systems Thinking”.',\n",
       " 'They will be then equipped with the knowledge in the foundational courses in Computer Science including the courses that will lay out the Mathematics Foundation, Software Foundation, and Hardware Foundation, and one course in Professional Responsibilities and Ethics in CS.',\n",
       " 'After having the knowledge in the CS foundation courses, the students will continue their journey with the major courses, which are designed to cover the most important and basic knowledge in the major aspects in Computer Science including a series of six courses that prepare for them to pursue their studies in the concentration areas of Computer Science.']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "be_sentences = [] \n",
    "for sentence in sentences:\n",
    "    # use re.search() because we care if the sentence contains 'be' or not\n",
    "    contains_be = re.search(r'\\b(is|are|am|be|being|been|was|were)\\b', sentence)\n",
    "    if contains_be:\n",
    "        be_sentences.append(sentence)\n",
    "\n",
    "be_sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 2\n",
    "Build a unigram model and a bigram model (both are with add-one smoothing) from the training data file. Then calculate and compare the perplexity score of these two models\n",
    "on the testing data file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build model \n",
    "- Tokenize training data\n",
    "- Count frequency of each ngram \n",
    "- Apply add-one smoothing on the ngram count \n",
    "\n",
    "Train model\n",
    "- Compute ngram probability on training data after smoothing\n",
    "- To handle unseen token: ignore \n",
    "\n",
    "Test model\n",
    "- Tokenize test data \n",
    "- Compute probability of seeing the test sentence -- do computation in log space\n",
    "- Save the average log likelihood & return it \n",
    "\n",
    "Compute Perplexity\n",
    "- Compute perplexity: exponentiate negative average log likelihood (avoid underflow, and adding is faster in previous step)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$PPL = exp\\large(-\\frac{1}{n}\\sum_i^n log P(w_i | w_{1:i-1})\\large)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unigram & add-one smoothing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unigrams: 742\n",
      "Number of unique unigrams: 302\n"
     ]
    }
   ],
   "source": [
    "unigrams = nltk.tokenize.word_tokenize(train) \n",
    "n_unigrams = len(unigrams)\n",
    "\n",
    "unique_unigrams = set(unigrams) \n",
    "n_unique_unigrams = len(unique_unigrams)\n",
    "\n",
    "print(f\"Number of unigrams: {n_unigrams}\\nNumber of unique unigrams: {n_unique_unigrams}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ngram_count(n, ngrams): \n",
    "    '''ngram is tokenized data'''\n",
    "    counts = {} \n",
    "    counts['<UNK>'] = 0\n",
    "    last_start = len(ngrams) - n + 1 \n",
    "\n",
    "    for i in range(last_start): \n",
    "        ngram = tuple(ngrams[i:i+n])\n",
    "        if ngram in counts.keys():\n",
    "            counts[ngram] += 1\n",
    "        else:\n",
    "            counts[ngram] = 1\n",
    "    \n",
    "    return counts \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$P_{Laplace}(w_i) = \\frac{c_i+1}{N+V}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_one_smoothing(ngrams_count, N, V): \n",
    "    '''N: Number of word token, V: vocab size (unique ngram)\n",
    "    this function returns dictionary of ngram probabilities \n",
    "    after applying Laplace smoothing. \n",
    "    '''\n",
    "    ngrams_prob = {} \n",
    "    ngrams_prob['<UNK>'] = 1 / (N + V)\n",
    "\n",
    "    for ngram in ngrams_count.keys(): \n",
    "        ci = ngrams_count[ngram]\n",
    "        ngrams_prob[ngram] = (ci + 1) / (N + V)\n",
    "    \n",
    "    return ngrams_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'<UNK>': 0.0009578544061302681,\n",
       " ('The',): 0.0028735632183908046,\n",
       " ('Computer',): 0.009578544061302681,\n",
       " ('Science',): 0.01053639846743295,\n",
       " ('major',): 0.008620689655172414,\n",
       " ('prepares',): 0.0019157088122605363,\n",
       " ('students',): 0.009578544061302681,\n",
       " ('with',): 0.006704980842911878,\n",
       " ('an',): 0.005747126436781609,\n",
       " ('adaptable',): 0.0019157088122605363,\n",
       " ('skill',): 0.0019157088122605363,\n",
       " ('set',): 0.0019157088122605363,\n",
       " ('to',): 0.020114942528735632,\n",
       " ('respond',): 0.0019157088122605363,\n",
       " ('the',): 0.029693486590038315,\n",
       " ('astonishing',): 0.0019157088122605363,\n",
       " ('speed',): 0.0019157088122605363,\n",
       " ('of',): 0.022030651340996167,\n",
       " ('technological',): 0.0019157088122605363,\n",
       " ('change',): 0.0019157088122605363,\n",
       " ('and',): 0.03639846743295019,\n",
       " ('develop',): 0.0028735632183908046,\n",
       " ('solutions',): 0.0019157088122605363,\n",
       " ('for',): 0.009578544061302681,\n",
       " ('problems',): 0.0038314176245210726,\n",
       " ('today',): 0.0019157088122605363,\n",
       " ('tomorrow',): 0.0019157088122605363,\n",
       " ('.',): 0.03065134099616858,\n",
       " ('Using',): 0.0019157088122605363,\n",
       " ('a',): 0.007662835249042145,\n",
       " ('student-centered',): 0.0019157088122605363,\n",
       " (',',): 0.05076628352490421,\n",
       " ('interdisciplinary',): 0.0019157088122605363,\n",
       " ('future-focused',): 0.0019157088122605363,\n",
       " ('approach',): 0.0028735632183908046,\n",
       " ('aims',): 0.0019157088122605363,\n",
       " ('educate',): 0.0019157088122605363,\n",
       " ('next',): 0.0019157088122605363,\n",
       " ('generation',): 0.0019157088122605363,\n",
       " ('local',): 0.0019157088122605363,\n",
       " ('leaders',): 0.0019157088122605363,\n",
       " ('who',): 0.0019157088122605363,\n",
       " ('will',): 0.012452107279693486,\n",
       " ('make',): 0.0019157088122605363,\n",
       " ('meaningful',): 0.0019157088122605363,\n",
       " ('lasting',): 0.0019157088122605363,\n",
       " ('societal',): 0.0019157088122605363,\n",
       " ('impact',): 0.0019157088122605363,\n",
       " ('both',): 0.0019157088122605363,\n",
       " ('in',): 0.02681992337164751,\n",
       " ('Vietnam',): 0.0019157088122605363,\n",
       " ('–',): 0.0028735632183908046,\n",
       " ('one',): 0.0028735632183908046,\n",
       " ('most',): 0.0028735632183908046,\n",
       " ('quickly',): 0.0019157088122605363,\n",
       " ('emerging',): 0.0028735632183908046,\n",
       " ('innovative',): 0.0019157088122605363,\n",
       " ('technology',): 0.0019157088122605363,\n",
       " ('economies',): 0.0019157088122605363,\n",
       " ('world',): 0.0019157088122605363,\n",
       " ('beyond',): 0.0028735632183908046,\n",
       " ('As',): 0.0019157088122605363,\n",
       " ('part',): 0.0028735632183908046,\n",
       " ('be',): 0.004789272030651341,\n",
       " ('equipped',): 0.0028735632183908046,\n",
       " ('foundational',): 0.0038314176245210726,\n",
       " ('knowledge',): 0.006704980842911878,\n",
       " ('relevant',): 0.0019157088122605363,\n",
       " ('disciplines',): 0.0028735632183908046,\n",
       " ('They',): 0.0038314176245210726,\n",
       " ('exposed',): 0.0028735632183908046,\n",
       " ('essential',): 0.0028735632183908046,\n",
       " ('areas',): 0.005747126436781609,\n",
       " ('CS',): 0.004789272030651341,\n",
       " ('discipline',): 0.0028735632183908046,\n",
       " ('including',): 0.004789272030651341,\n",
       " ('theory',): 0.0028735632183908046,\n",
       " ('systems',): 0.004789272030651341,\n",
       " ('applications',): 0.004789272030651341,\n",
       " ('learn',): 0.0028735632183908046,\n",
       " ('about',): 0.0019157088122605363,\n",
       " ('underlying',): 0.0019157088122605363,\n",
       " ('mathematical',): 0.0019157088122605363,\n",
       " ('ideas',): 0.0019157088122605363,\n",
       " ('that',): 0.0038314176245210726,\n",
       " ('are',): 0.0038314176245210726,\n",
       " ('critical',): 0.0019157088122605363,\n",
       " ('computation',): 0.0028735632183908046,\n",
       " ('establish',): 0.0019157088122605363,\n",
       " ('proficiency',): 0.0019157088122605363,\n",
       " ('process',): 0.0019157088122605363,\n",
       " ('designing',): 0.0019157088122605363,\n",
       " ('gain',): 0.0028735632183908046,\n",
       " ('experience',): 0.0028735632183908046,\n",
       " ('collecting',): 0.0019157088122605363,\n",
       " ('analyzing',): 0.0019157088122605363,\n",
       " ('data',): 0.004789272030651341,\n",
       " ('using',): 0.0019157088122605363,\n",
       " ('modern',): 0.0019157088122605363,\n",
       " ('technologies',): 0.0019157088122605363,\n",
       " ('begin',): 0.0019157088122605363,\n",
       " ('understanding',): 0.0028735632183908046,\n",
       " ('role',): 0.0019157088122605363,\n",
       " ('users',): 0.0019157088122605363,\n",
       " ('design',): 0.0019157088122605363,\n",
       " ('Courses',): 0.0019157088122605363,\n",
       " ('go',): 0.0019157088122605363,\n",
       " ('content',): 0.0019157088122605363,\n",
       " ('help',): 0.0019157088122605363,\n",
       " ('through',): 0.0028735632183908046,\n",
       " ('direct',): 0.0019157088122605363,\n",
       " ('experiences',): 0.0019157088122605363,\n",
       " ('projects',): 0.0038314176245210726,\n",
       " ('In',): 0.0028735632183908046,\n",
       " ('future',): 0.0019157088122605363,\n",
       " ('they',): 0.0028735632183908046,\n",
       " ('also',): 0.0028735632183908046,\n",
       " ('have',): 0.0028735632183908046,\n",
       " ('opportunity',): 0.0028735632183908046,\n",
       " ('further',): 0.0019157088122605363,\n",
       " ('focus',): 0.0019157088122605363,\n",
       " ('their',): 0.01053639846743295,\n",
       " ('studies',): 0.0038314176245210726,\n",
       " ('by',): 0.0028735632183908046,\n",
       " ('selecting',): 0.0019157088122605363,\n",
       " ('concentration',): 0.0028735632183908046,\n",
       " ('such',): 0.0019157088122605363,\n",
       " ('as',): 0.004789272030651341,\n",
       " ('science',): 0.007662835249042145,\n",
       " ('artificial',): 0.0038314176245210726,\n",
       " ('intelligence',): 0.0038314176245210726,\n",
       " ('machine',): 0.0038314176245210726,\n",
       " ('learning',): 0.005747126436781609,\n",
       " ('business',): 0.0038314176245210726,\n",
       " ('analytics',): 0.0028735632183908046,\n",
       " ('digital',): 0.0038314176245210726,\n",
       " ('media',): 0.0038314176245210726,\n",
       " ('software',): 0.0028735632183908046,\n",
       " ('engineering',): 0.0028735632183908046,\n",
       " ('at',): 0.0028735632183908046,\n",
       " ('Fulbright',): 0.0038314176245210726,\n",
       " ('is',): 0.0019157088122605363,\n",
       " ('designed',): 0.0028735632183908046,\n",
       " ('prepare',): 0.0028735632183908046,\n",
       " ('work',): 0.0028735632183908046,\n",
       " ('industry',): 0.0028735632183908046,\n",
       " ('or',): 0.0019157088122605363,\n",
       " ('continue',): 0.0038314176245210726,\n",
       " ('lifelong',): 0.0028735632183908046,\n",
       " ('well',): 0.0019157088122605363,\n",
       " ('potential',): 0.0019157088122605363,\n",
       " ('graduate-level',): 0.0019157088122605363,\n",
       " ('Students',): 0.0028735632183908046,\n",
       " (':',): 0.0028735632183908046,\n",
       " ('1',): 0.0019157088122605363,\n",
       " ('Think',): 0.0019157088122605363,\n",
       " ('computationally',): 0.0019157088122605363,\n",
       " ('critically',): 0.0019157088122605363,\n",
       " ('analyze',): 0.0019157088122605363,\n",
       " ('decompose',): 0.0019157088122605363,\n",
       " ('evaluate',): 0.0019157088122605363,\n",
       " ('solve',): 0.0019157088122605363,\n",
       " ('2',): 0.0028735632183908046,\n",
       " ('Demonstrate',): 0.0019157088122605363,\n",
       " ('computer',): 0.004789272030651341,\n",
       " ('3',): 0.0019157088122605363,\n",
       " ('Explain',): 0.0019157088122605363,\n",
       " ('aspects',): 0.0028735632183908046,\n",
       " ('(',): 0.0038314176245210726,\n",
       " ('e.g.',): 0.0028735632183908046,\n",
       " ('etc.',): 0.0028735632183908046,\n",
       " (')',): 0.0038314176245210726,\n",
       " ('4',): 0.0019157088122605363,\n",
       " ('Practice',): 0.0019157088122605363,\n",
       " ('collaboration',): 0.0019157088122605363,\n",
       " ('communication',): 0.0019157088122605363,\n",
       " ('skills',): 0.0019157088122605363,\n",
       " ('evolving',): 0.0019157088122605363,\n",
       " ('5',): 0.0019157088122605363,\n",
       " ('Apply',): 0.0019157088122605363,\n",
       " ('different',): 0.0019157088122605363,\n",
       " ('mathematics',): 0.0019157088122605363,\n",
       " ('’',): 0.0028735632183908046,\n",
       " ('s',): 0.0028735632183908046,\n",
       " ('unique',): 0.0019157088122605363,\n",
       " ('liberal',): 0.0019157088122605363,\n",
       " ('arts',): 0.0019157088122605363,\n",
       " ('6',): 0.0019157088122605363,\n",
       " ('Produce',): 0.0019157088122605363,\n",
       " ('portfolio',): 0.0019157088122605363,\n",
       " ('tangible',): 0.0019157088122605363,\n",
       " ('apps',): 0.0019157088122605363,\n",
       " ('community-service',): 0.0019157088122605363,\n",
       " ('capstone',): 0.0019157088122605363,\n",
       " ('7',): 0.0019157088122605363,\n",
       " ('Prepare',): 0.0019157088122605363,\n",
       " ('cutting',): 0.0019157088122605363,\n",
       " ('edge',): 0.0019157088122605363,\n",
       " ('developing',): 0.0019157088122605363,\n",
       " ('careers',): 0.0019157088122605363,\n",
       " ('competitive',): 0.0019157088122605363,\n",
       " ('graduate',): 0.0019157088122605363,\n",
       " ('professional',): 0.0019157088122605363,\n",
       " ('study',): 0.0028735632183908046,\n",
       " ('top-tier',): 0.0019157088122605363,\n",
       " ('international',): 0.0019157088122605363,\n",
       " ('programs',): 0.0019157088122605363,\n",
       " ('All',): 0.0019157088122605363,\n",
       " ('first',): 0.0019157088122605363,\n",
       " ('required',): 0.0019157088122605363,\n",
       " ('take',): 0.0019157088122605363,\n",
       " ('core',): 0.0028735632183908046,\n",
       " ('courses',): 0.014367816091954023,\n",
       " ('Liberal',): 0.0019157088122605363,\n",
       " ('Arts',): 0.0019157088122605363,\n",
       " ('addition',): 0.0019157088122605363,\n",
       " ('two',): 0.0019157088122605363,\n",
       " ('“',): 0.005747126436781609,\n",
       " ('Global',): 0.0019157088122605363,\n",
       " ('Humanities',): 0.0019157088122605363,\n",
       " ('Social',): 0.0019157088122605363,\n",
       " ('Change',): 0.0019157088122605363,\n",
       " ('”',): 0.005747126436781609,\n",
       " ('Modern',): 0.0019157088122605363,\n",
       " ('Vietnamese',): 0.0019157088122605363,\n",
       " ('Culture',): 0.0019157088122605363,\n",
       " ('Society',): 0.0019157088122605363,\n",
       " ('computational',): 0.0019157088122605363,\n",
       " ('thinking',): 0.0019157088122605363,\n",
       " ('undergraduate',): 0.0019157088122605363,\n",
       " ('Quantitative',): 0.0019157088122605363,\n",
       " ('Reasoning',): 0.0019157088122605363,\n",
       " ('Digital',): 0.0019157088122605363,\n",
       " ('Age.',): 0.0019157088122605363,\n",
       " ('Scientific',): 0.0019157088122605363,\n",
       " ('Inquiry',): 0.0019157088122605363,\n",
       " ('Design',): 0.0019157088122605363,\n",
       " ('Systems',): 0.0019157088122605363,\n",
       " ('Thinking',): 0.0019157088122605363,\n",
       " ('Exploratory',): 0.0019157088122605363,\n",
       " ('encourage',): 0.0019157088122605363,\n",
       " ('step',): 0.0019157088122605363,\n",
       " ('out',): 0.0028735632183908046,\n",
       " ('comfort',): 0.0019157088122605363,\n",
       " ('zone',): 0.0019157088122605363,\n",
       " ('exploring',): 0.0019157088122605363,\n",
       " ('broad',): 0.0019157088122605363,\n",
       " ('discover',): 0.0019157088122605363,\n",
       " ('more',): 0.0019157088122605363,\n",
       " ('fully',): 0.0019157088122605363,\n",
       " ('where',): 0.0019157088122605363,\n",
       " ('interests',): 0.0019157088122605363,\n",
       " ('passions',): 0.0019157088122605363,\n",
       " ('lay',): 0.0028735632183908046,\n",
       " ('need',): 0.0019157088122605363,\n",
       " ('complete',): 0.0019157088122605363,\n",
       " ('8',): 0.0019157088122605363,\n",
       " ('credits',): 0.0019157088122605363,\n",
       " ('chosen',): 0.0019157088122605363,\n",
       " ('from',): 0.0019157088122605363,\n",
       " ('each',): 0.0019157088122605363,\n",
       " ('course',): 0.0028735632183908046,\n",
       " ('category',): 0.0019157088122605363,\n",
       " ('then',): 0.0019157088122605363,\n",
       " ('Mathematics',): 0.0019157088122605363,\n",
       " ('Foundation',): 0.0038314176245210726,\n",
       " ('Software',): 0.0019157088122605363,\n",
       " ('Hardware',): 0.0019157088122605363,\n",
       " ('Professional',): 0.0019157088122605363,\n",
       " ('Responsibilities',): 0.0019157088122605363,\n",
       " ('Ethics',): 0.0019157088122605363,\n",
       " ('These',): 0.0019157088122605363,\n",
       " ('provide',): 0.0019157088122605363,\n",
       " ('build',): 0.0019157088122605363,\n",
       " ('solid',): 0.0019157088122605363,\n",
       " ('base',): 0.0019157088122605363,\n",
       " ('while',): 0.0019157088122605363,\n",
       " ('permitting',): 0.0019157088122605363,\n",
       " ('non-majors',): 0.0019157088122605363,\n",
       " ('pursue',): 0.0028735632183908046,\n",
       " ('interest',): 0.0028735632183908046,\n",
       " ('After',): 0.0019157088122605363,\n",
       " ('having',): 0.0019157088122605363,\n",
       " ('foundation',): 0.0028735632183908046,\n",
       " ('journey',): 0.0019157088122605363,\n",
       " ('which',): 0.0019157088122605363,\n",
       " ('cover',): 0.0019157088122605363,\n",
       " ('important',): 0.0019157088122605363,\n",
       " ('basic',): 0.0019157088122605363,\n",
       " ('series',): 0.0019157088122605363,\n",
       " ('six',): 0.0019157088122605363,\n",
       " ('them',): 0.0019157088122605363,\n",
       " ('Following',): 0.0019157088122605363,\n",
       " ('completion',): 0.0019157088122605363,\n",
       " ('flexibility',): 0.0019157088122605363,\n",
       " ('choice',): 0.0019157088122605363,\n",
       " ('elective/concentration',): 0.0019157088122605363,\n",
       " ('on',): 0.0019157088122605363,\n",
       " ('Potential',): 0.0019157088122605363,\n",
       " ('concentrations',): 0.0019157088122605363,\n",
       " ('include',): 0.0019157088122605363,\n",
       " ('security',): 0.0019157088122605363,\n",
       " ('etc',): 0.0019157088122605363}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unigrams_count = ngram_count(1, unigrams)\n",
    "unigrams_prob = add_one_smoothing(unigrams_count, n_unigrams, n_unique_unigrams)\n",
    "\n",
    "unigrams_prob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"testing\" model ở đây là predict value? no, it's like we skip the \"test\" phase and go straight to evaluation after training model? there is no labelled data to test? just go to compute log likelihood and perplexity now? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_unigrams = nltk.tokenize.word_tokenize(test)\n",
    "n_test_unigrams = len(test_unigrams)\n",
    "\n",
    "test_unique_unigrams = set(test_unigrams) \n",
    "n_test_unique_unigrams = len(test_unique_unigrams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_unigrams_count = ngram_count(1, test_unigrams)\n",
    "test_unigrams_prob = add_one_smoothing(test_unigrams_count, n_test_unigrams, n_test_unique_unigrams)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the case of unigram model: \n",
    "\n",
    "$$P(sentence | model) = \\prod_{i}^{N} P(word_i | model) \\\\\n",
    "\\Leftrightarrow ln P(sentence | model) = \\sum_{i}^{N} ln P(word_i | model) \\\\\n",
    "\\Leftrightarrow ln P(sentence | model) = \\sum_{i}^{N} count(word_i) * ln P(word_i | model)  \n",
    "$$\n",
    "\n",
    "Dòng 1 và dòng 2 là em tự viết. Dòng cuối trong 3 dòng toán này là đáp án em hỏi GPT-4, thực ra em thấy nó rất intuitive và dễ hiểu, bởi vì một từ càng xuât hiện nhiều thì nó càng nên tăng log likelihood của từ đó, nhưng em chưa thấy chỗ nào viết cồng thức ở dòng 3 explicitly ra cả. Em có tìm thêm để cố gắng justify dòng 3 thì có Wikipedia viết là: \n",
    "\n",
    "\n",
    "\"Given the independence of each event, the overall log-likelihood of intersection equals the sum of the log-likelihoods of the individual events. This is analogous to the fact that the overall log-probability is the sum of the log-probability of the individual events.\"\n",
    "\n",
    "Anh có hiểu vì sao ko? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math \n",
    "\n",
    "def log_likelihood(ngrams_count, ngrams_prob, N):\n",
    "    logllh = 0 \n",
    "\n",
    "    for ngram in ngrams_count.keys(): \n",
    "        count = ngrams_count[ngram] \n",
    "        prob = ngrams_prob[ngram]\n",
    "        logllh += count * math.log2(prob)\n",
    "    \n",
    "    return logllh / N "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perplexity(avglogllh):\n",
    "    return pow(2, (-1)*avglogllh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unigram_ppl(unigrams, n_unigrams, unigram_probability):\n",
    "    test_ppl = 1\n",
    "\n",
    "    for unigram in unigrams:\n",
    "        if unigram in unigram_probability.keys():\n",
    "            test_ppl *= 1/unigram_probability[unigram]\n",
    "        else: \n",
    "            test_ppl *= 1/unigram_probability['<UNK>']\n",
    "\n",
    "    test_ppl = test_ppl ** (1/n_unigrams)\n",
    "    return test_ppl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1043.9999999999998"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_manual_perplexity = unigram_ppl(test_unigrams, n_test_unigrams, unigrams_prob)\n",
    "test_manual_perplexity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "31.205498836801908"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_avg_logllh = log_likelihood(test_unigrams_count, test_unigrams_prob, n_test_unigrams)\n",
    "test_logllh_perplexity = perplexity(test_avg_logllh)\n",
    "test_logllh_perplexity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def calculate_perplexity(unigram_probs, test_set):\n",
    "    entropy = 0\n",
    "    for word in test_set:\n",
    "        if word in unigram_probs:\n",
    "            entropy += math.log(unigram_probs[word], 2)\n",
    "        else:\n",
    "            entropy += math.log(1/len(unigram_probs), 2)  # handling unknown words\n",
    "    entropy = -entropy / len(test_set)\n",
    "    perplexity = math.pow(2, entropy)\n",
    "    return perplexity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "302.99999999998823"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calculate_perplexity(unigrams_prob, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_perplexity_on_test_set(model, tokenized_test_sentences ):\n",
    "    perplexity = 1\n",
    "    N = len(tokenized_test_sentences)\n",
    "\n",
    "    for sentence in tokenized_test_sentences:\n",
    "        for word in sentence:\n",
    "            perplexity *= (1/model[word])\n",
    "\n",
    "    perplexity = pow(perplexity, 1/float(N))\n",
    "    return perplexity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'A'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[44], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mcompute_perplexity_on_test_set\u001b[49m\u001b[43m(\u001b[49m\u001b[43munigrams_prob\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_unigrams\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[43], line 7\u001b[0m, in \u001b[0;36mcompute_perplexity_on_test_set\u001b[0;34m(model, tokenized_test_sentences)\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m sentence \u001b[38;5;129;01min\u001b[39;00m tokenized_test_sentences:\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m word \u001b[38;5;129;01min\u001b[39;00m sentence:\n\u001b[0;32m----> 7\u001b[0m         perplexity \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m=\u001b[39m (\u001b[38;5;241m1\u001b[39m\u001b[38;5;241m/\u001b[39m\u001b[43mmodel\u001b[49m\u001b[43m[\u001b[49m\u001b[43mword\u001b[49m\u001b[43m]\u001b[49m)\n\u001b[1;32m      9\u001b[0m perplexity \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mpow\u001b[39m(perplexity, \u001b[38;5;241m1\u001b[39m\u001b[38;5;241m/\u001b[39m\u001b[38;5;28mfloat\u001b[39m(N))\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m perplexity\n",
      "\u001b[0;31mKeyError\u001b[0m: 'A'"
     ]
    }
   ],
   "source": [
    "compute_perplexity_on_test_set(unigrams_prob, test_unigrams)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Em implement cái gì sai vậy mà sao nó ra khác nhau quá trời TvT "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bigram & add-one smoothing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('The', 'Computer'),\n",
       " ('Computer', 'Science'),\n",
       " ('Science', 'major'),\n",
       " ('major', 'prepares'),\n",
       " ('prepares', 'students'),\n",
       " ('students', 'with'),\n",
       " ('with', 'an'),\n",
       " ('an', 'adaptable'),\n",
       " ('adaptable', 'skill'),\n",
       " ('skill', 'set')]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bigrams = [] \n",
    "for i in range(len(unigrams)-1):\n",
    "    context = unigrams[i]\n",
    "    word = unigrams[i+1]\n",
    "    bigram = (context, word)\n",
    "    bigrams.append(bigram)\n",
    "\n",
    "bigrams[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the same training corpus, bigram has significantly lower perplexity score of \n",
    "2.0643605162383167 compared to unigram with perplexity score of 37.57928459350777. \n",
    "\n",
    "Bigram performs better on test set. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Intermediate results for Question 2"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
