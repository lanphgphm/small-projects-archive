{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re \n",
    "import pandas as pd \n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_treebank(treebank_str):\n",
    "    treebank_str = treebank_str.replace(\"\\n\", \"\")\n",
    "    treebank_str = treebank_str.replace(\"=\", \"\")\n",
    "    treebank_str = treebank_str.replace(\"[\", \"\")\n",
    "    treebank_str = treebank_str.replace(\"]\", \"\")\n",
    "    treebank_str = treebank_str.strip()\n",
    "    return treebank_str\n",
    "\n",
    "def parse_treebank(treebank_str): \n",
    "    pattern = re.compile(r\"(\\S+)/(\\S+)\")\n",
    "    tree_sents = treebank_str.split(\"\\n\\n\")\n",
    "    parsed_sents = [] \n",
    "    \n",
    "\n",
    "    for sent in tree_sents: \n",
    "        sent = preprocess_treebank(sent)\n",
    "        parsed_sent = [] \n",
    "        parsed_sent.append((\"<s>\", \"<s>\"))\n",
    "        tokens = sent.split(\" \")\n",
    "\n",
    "        for token in tokens: \n",
    "            match = pattern.match(token)\n",
    "\n",
    "            if (match): \n",
    "                delim_idx = token.find(\"/\")\n",
    "                word = token[:delim_idx]\n",
    "                tag = token[delim_idx+1:]\n",
    "                parsed_sent.append((word, tag))\n",
    "        parsed_sent.append((\"<e>\", \"<e>\"))\n",
    "\n",
    "        if len(parsed_sent) > 2:\n",
    "            parsed_sents.append(parsed_sent)\n",
    "\n",
    "    return parsed_sents\n",
    "\n",
    "def get_tags_count(documents):\n",
    "    tags = defaultdict(int)\n",
    "    pair_tags = defaultdict(int)\n",
    "\n",
    "    for doc in documents: \n",
    "        for parsed_word in doc: \n",
    "            tag = parsed_word[1]\n",
    "            tags[tag] += 1\n",
    "        \n",
    "        for i in range(len(doc)-1): \n",
    "            tag1 = doc[i][1]\n",
    "            tag2 = doc[i+1][1]\n",
    "            pair_tags[(tag1, tag2)] += 1\n",
    "    return tags, pair_tags\n",
    "\n",
    "def get_emit_count(documents): \n",
    "    emit_count = defaultdict(int)\n",
    "\n",
    "    for doc in documents: \n",
    "        for (word, tag) in doc: \n",
    "            emit_count[(word, tag)] += 1\n",
    "    \n",
    "    return emit_count\n",
    "\n",
    "def get_vocabulary(documents):\n",
    "    vocab = set()\n",
    "    for doc in documents: \n",
    "        for parsed_word in doc: \n",
    "            word = parsed_word[0]\n",
    "            vocab.add(word)\n",
    "    return list(vocab)\n",
    "\n",
    "def get_transition_matrix(documents):\n",
    "    tags, pair_tags = get_tags_count(documents)\n",
    "\n",
    "    trans = pd.DataFrame(0, index=tags, columns=tags)\n",
    "    for doc in documents: \n",
    "        for i in range(len(doc)-1): \n",
    "            left_tag = doc[i][1]\n",
    "            right_tag = doc[i+1][1]\n",
    "\n",
    "            count_left_to_right = pair_tags[(left_tag, right_tag)]\n",
    "            count_left = tags[left_tag]\n",
    "\n",
    "            prob_left_to_right = count_left_to_right / count_left\n",
    "            trans.loc[left_tag, right_tag]= prob_left_to_right\n",
    "    \n",
    "    return trans\n",
    "\n",
    "def get_emission_matrix(documents): \n",
    "    tags, _ = get_tags_count(documents)\n",
    "    emit_count = get_emit_count(documents)\n",
    "    vocab = get_vocabulary(documents)\n",
    "\n",
    "    emit = pd.DataFrame(0, index=tags, columns=vocab)\n",
    "    for doc in documents: \n",
    "        for (word, tag) in doc: \n",
    "            count_emit = emit_count[(word, tag)]\n",
    "            count_tag = tags[tag]\n",
    "\n",
    "            emit_prob = count_emit / count_tag\n",
    "            emit.loc[tag, word] = emit_prob\n",
    "    \n",
    "    return emit\n",
    "\n",
    "def get_initial_state_matrix(documents):\n",
    "    tags, _ = get_tags_count(documents)\n",
    "    init = pd.Series(0, index=tags)\n",
    "    for doc in documents: \n",
    "        tag = doc[0][1]\n",
    "        init[tag] += 1\n",
    "    init = init / init.sum()\n",
    "    return init\n",
    "\n",
    "\n",
    "def parse_treebank_file(filepath): \n",
    "    with open(filepath, \"r\") as f: \n",
    "        treebank_str = f.read() \n",
    "        return parse_treebank(treebank_str)\n",
    "\n",
    "def get_file_id(i): \n",
    "    return f\"{i:04d}\"\n",
    "\n",
    "\n",
    "def read_all_treebank_files(n_files, file_dir=\"./treebank/tagged\"): \n",
    "    all_documents = []\n",
    "    for i in range(1, n_files+1): \n",
    "        file_id = get_file_id(i)\n",
    "        filepath = f\"{file_dir}/wsj_{file_id}.pos\"\n",
    "        documents = parse_treebank_file(filepath)\n",
    "        all_documents.extend(documents)\n",
    "    return all_documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HiddenMarkovModel: \n",
    "    def __init__(self, treebank_dir, n_files): \n",
    "        self.all_docs = read_all_treebank_files(n_files, treebank_dir)\n",
    "\n",
    "        self.trans = get_transition_matrix(self.all_docs)\n",
    "        self.emit = get_emission_matrix(self.all_docs)\n",
    "        self.pi = get_initial_state_matrix(self.all_docs)\n",
    "        \n",
    "        self.states = list(self.emit.index)\n",
    "        self.vocab = list(self.emit.columns)\n",
    "\n",
    "        self.n_states = len(self.states)\n",
    "        self.n_vocab = len(self.vocab)\n",
    "        \n",
    "    def preprocess_obs(self, obs): \n",
    "        obs = \"<s> \" + obs + \" <e>\"\n",
    "        return obs \n",
    "    \n",
    "    def viterbi(self, obs): \n",
    "        proc_obs = self.preprocess_obs(obs)\n",
    "        obs_list = proc_obs.split(\" \")\n",
    "        n_obs = len(obs_list)\n",
    "        V = pd.DataFrame(0, index=self.states, columns=obs_list)\n",
    "        prev = pd.DataFrame(0, index=self.states, columns=obs_list)\n",
    "        \n",
    "        for tag in self.states:\n",
    "            first_ob = obs_list[0]\n",
    "            V.loc[tag, first_ob] = self.pi[tag] * self.emit.loc[tag, first_ob]\n",
    "\n",
    "        print(V)\n",
    "\n",
    "        for t in range(1, n_obs): \n",
    "            ob = obs_list[t]\n",
    "            prev_ob = obs_list[t-1]\n",
    "            for cur_state in self.states: \n",
    "                for prev_state in self.states: \n",
    "                    new_prob = V.loc[prev_state, prev_ob] * self.trans.loc[prev_state, cur_state] * self.emit.loc[cur_state, ob]\n",
    "                    if new_prob > V.loc[cur_state, ob]:\n",
    "                        V.loc[cur_state, ob] = new_prob\n",
    "                        prev.loc[cur_state, ob] = prev_state\n",
    "\n",
    "        # reconstruct the most likely sequence and return it \n",
    "        path = [] \n",
    "        path_prob = -0.1\n",
    "        final_state = None\n",
    "\n",
    "        print(V)\n",
    "\n",
    "        for state in self.states: \n",
    "            if V.loc[state, obs_list[-1]] > path_prob: \n",
    "                path_prob = V.loc[state, obs_list[-1]]\n",
    "                print(path_prob)\n",
    "                final_state = state\n",
    "                print(final_state)\n",
    "\n",
    "        path.append(final_state)\n",
    "\n",
    "        for t in range(n_obs-1, 0, -1):\n",
    "            if final_state is None: \n",
    "                print(\"Error: previous state is None\")\n",
    "                print(path)\n",
    "                break\n",
    "            final_state = prev.loc[final_state, obs_list[t]]\n",
    "            path.insert(0, final_state)\n",
    "        \n",
    "        return path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test HMM \n",
    "treebank_dir = \"./treebank/tagged\"\n",
    "n_files = 1\n",
    "hmm = HiddenMarkovModel(treebank_dir, n_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs = \"the chairman publishing group\"\n",
    "hmm.viterbi(obs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
